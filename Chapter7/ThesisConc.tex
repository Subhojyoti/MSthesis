In this thesis, we studied two complex bandit problems, the stochastic multi-armed bandit (SMAB) with the goal of cumulative regret minimization and pure exploration stochastic thresholding bandit problem (TBP) with the goal of expected loss minimization. For the first problem, we devised a novel algorithm called Efficient UCB Variance (EUCBV) which enjoys an order optimal regret bound and performs superbly in diverse stochastic environments. In the second part, the thresholding bandit problem, we came up with the novel algorithm called Augmented UCB (AugUCB) which is the first algorithm to use variance estimation for the considered TBP setting and also empirically outperforms most of the other algorithms. 

% and piecewise stationary bandits with the goal of finding adaptive algorithms which detect and adapts to changepoints
%Finally, we studied the piecewise stochastic bandits and proposed several solutions for adaptive algorithms that detect changepoints and try to adapt accordingly.

    

