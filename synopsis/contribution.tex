The main contributions of the thesis are as follows:-
\begin{enumerate}
\item We proposed a novel algorithm for the stochastic multi-armed bandit (MAB) problem. Our proposed Efficient UCB Variance method, referred to as EUCBV is an arm elimination algorithm based on UCB-Improved and UCBV strategy which takes into account the empirical variance of the arms and along with aggressive exploration factors eliminate sub-optimal arms. Through a theoretical analysis, we establish that EUCBV achieves a better gap-dependent regret upper bound than UCB-Improved, MOSS, UCB1, and UCBV algorithms. EUCBV enjoys an order optimal gap-independent regret bound same as that of OCUCB and MOSS, and better than UCB-Improved, UCB1 and UCBV. Empirically, in several environments EUCBV outperforms most of the state-of-the-art algorithms. 

\item We proposed the Augmented-UCB (AugUCB) algorithm for a fixed-budget version of the thresholding bandit problem (TBP), where the objective is to identify a set of arms whose quality is above a threshold. A key feature of AugUCB is that it uses both mean and variance estimates to eliminate arms that have been sufficiently explored. This is the first algorithm to employ such an approach for the considered TBP. Furthermore, in numerical evaluations we establish in several environments that AugUCB outperforms all the algorithms that does not take into consideration the variance of the arms in their action selection strategy.

%\item We proposed a general framework of bandit algorithms that combines change-point detection algorithm with aggregation of expert strategies in order to define efficient pulling strategies in context of the piecewise stochastic  distributions. The algorithms that we proposed for the piecewise stochastic setting are actively adaptive algorithms which performs very similarly to the oracle algorithm which has access to the changepoints and suffers no additional delay in adapting to the changing environment. 
\end{enumerate}
 