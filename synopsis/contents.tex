The proposed contents of the thesis from chapter 1 to chapter 6 are mentioned below.
\textbf{1. Introduction to Bandits}\\
1.1 Reinforcement Learning \\
1.2 Connection between Reinforcement Learning and Bandits \\
1.3 Why study Bandits?\\
1.4 Motivation \\
1.5 Types of Information Feedback\\
1.6 Different types of Bandits\\
1.7 Objectives of Thesis\\
1.8 Contributions of Thesis\\
1.9 Outline of the Thesis\\
\\
\textbf{2. Stochastic Multi-armed Bandits} \\
2.1 Introduction to SMAB\\
2.2 Notations and assumptions\\
2.3 Problem Definition\\
2.4 Motivation\\
2.5 Related Work in SMAB\\
2.6 Summary \\
\\
\textbf{3. Efficient UCB Variance: An almost optimal algorithm in SMAB setting}\\
3.1 Introduction\\
3.2 Our Contributions\\
3.3 Algorithm: Efficient UCB Variance\\
3.4 Main Results\\
3.5 Proofs\\
3.6 Experiments\\
3.7 Summary\\
\\
\textbf{4. Thresholding Bandits}\\
4.1 Introduction to TBP\\
4.2 Notations and assumptions\\
4.3 Problem Definition\\
4.4 Motivation\\
4.5 Related Work in Pure Exploration\\
4.6 TBP connection to Pure Exploration\\
4.7 Related Work in TBP \\
4.8 Summary\\
\\
\textbf{5. Augmented UCB for Thresholding Bandit Problem}\\
5.1 Introduction\\
5.2 Our Contributions\\
5.3 Augmented-UCB Algorithm\\
5.4 Theoretical Results\\
5.5 Numerical Experiments\\
5.6 Summary\\
\\
\textbf{6. Conclusions} \\
6.1 Conclusions and Future Directions \\
\\
\textbf{Appendix}\\
Appendix A\\
Appendix B\\